{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "af678947a58e493599351c88bef2ca8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1be715a9b1ff474eb21248862a42dda2",
              "IPY_MODEL_20f140c2329c445f9d9b2a6a5ec2e3a1",
              "IPY_MODEL_0806e3f728814596977d6842e93e207d"
            ],
            "layout": "IPY_MODEL_493587d9a56f429796e6b03bde7dab2b"
          }
        },
        "1be715a9b1ff474eb21248862a42dda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9685321472d49178d5bab06c826c9e2",
            "placeholder": "​",
            "style": "IPY_MODEL_f7fd79d431524b988bcbb0a801127314",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "20f140c2329c445f9d9b2a6a5ec2e3a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f4feddc51c4d77a5eeb9ad82f6b907",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9c4967ecb6f46899dd2cf34305eead1",
            "value": 0
          }
        },
        "0806e3f728814596977d6842e93e207d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c3d1dbce0b4115a947d959d95ec991",
            "placeholder": "​",
            "style": "IPY_MODEL_e563bcc4d44244cd8bb3a58d2ace20c1",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "493587d9a56f429796e6b03bde7dab2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9685321472d49178d5bab06c826c9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7fd79d431524b988bcbb0a801127314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2f4feddc51c4d77a5eeb9ad82f6b907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c4967ecb6f46899dd2cf34305eead1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96c3d1dbce0b4115a947d959d95ec991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e563bcc4d44244cd8bb3a58d2ace20c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tiWgqxCLCYOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d894f9-fd82-4e27-ec9b-092bffe30314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MedicalNet' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Tencent/MedicalNet.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUTocr__I_tX",
        "outputId": "2de264a8-f30e-4fdf-ea10-c8d41c9e3605"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the link below with the actual Google Drive ID for the pretrained model zip\n",
        "!gdown --id https://drive.google.com/file/d/145ZEW3A6isY3gjYYiYomNj9Az-yVd-p_/view?usp=sharing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reumHBGXJEis",
        "outputId": "2893682c-e1c9-49c5-9afe-5b9fc9540e1f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=https://drive.google.com/file/d/145ZEW3A6isY3gjYYiYomNj9Az-yVd-p_/view?usp=sharing\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/MedicalNet_pytorch_files2.zip /content/\n"
      ],
      "metadata": {
        "id": "Q2-0Bd7yJJBI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MedicalNet\n",
        "!unzip /content/drive/MyDrive/MedicalNet_pytorch_files2.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbgmeT1tMszS",
        "outputId": "7934d84d-33e5-490b-b1a3-21bc47ba3000"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedicalNet\n",
            "Archive:  /content/drive/MyDrive/MedicalNet_pytorch_files2.zip\n",
            "   creating: data/\n",
            "   creating: data/MRBrainS18/\n",
            "   creating: data/MRBrainS18/images/\n",
            "  inflating: data/MRBrainS18/images/070.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/1.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/14.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/148.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/4.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/5.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/7.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/71.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/72.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/73.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/74.nii.gz  \n",
            "  inflating: data/MRBrainS18/images/75.nii.gz  \n",
            "   creating: data/MRBrainS18/labels/\n",
            "  inflating: data/MRBrainS18/labels/070.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/1.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/14.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/148.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/4.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/5.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/7.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/71.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/72.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/73.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/74.nii.gz  \n",
            "  inflating: data/MRBrainS18/labels/75.nii.gz  \n",
            "  inflating: data/train.txt          \n",
            "  inflating: data/val.txt            \n",
            "   creating: pretrain/\n",
            "  inflating: pretrain/resnet_10.pth  \n",
            "  inflating: pretrain/resnet_101.pth  \n",
            "  inflating: pretrain/resnet_10_23dataset.pth  \n",
            "  inflating: pretrain/resnet_152.pth  \n",
            "  inflating: pretrain/resnet_18.pth  \n",
            "  inflating: pretrain/resnet_18_23dataset.pth  \n",
            "  inflating: pretrain/resnet_200.pth  \n",
            "  inflating: pretrain/resnet_34.pth  \n",
            "  inflating: pretrain/resnet_34_23dataset.pth  \n",
            "  inflating: pretrain/resnet_50.pth  \n",
            "  inflating: pretrain/resnet_50_23dataset.pth  \n",
            "   creating: trails/\n",
            "   creating: trails/models/\n",
            "  inflating: trails/models/resnet_50_epoch_110_batch_0.pth.tar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single GPU training\n",
        "!python /content/MedicalNet/train.py --gpu_id 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvTY4oArNS-R",
        "outputId": "a0537d1e-7d6e-45ce-ff5d-d1cb32c319dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedicalNet/models/resnet.py:173: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
            "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
            "loading pretrained model pretrain/resnet_50.pth\n",
            "/content/MedicalNet/model.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pretrain = torch.load(opt.pretrain_path)\n",
            "DataParallel(\n",
            "  (module): ResNet(\n",
            "    (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
            "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
            "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
            "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
            "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
            "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
            "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
            "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
            "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
            "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
            "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
            "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv_seg): Sequential(\n",
            "      (0): ConvTranspose3d(2048, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
            "      (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Processing 10 datas\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2024-11-08 14:38:11 INFO     [train.py:23] 200 epochs in total, 10 batches per epoch\n",
            "Current setting is:\n",
            "Namespace(data_root='./data', img_list='./data/train.txt', n_seg_classes=2, learning_rate=0.001, num_workers=4, batch_size=1, phase='train', save_intervals=10, n_epochs=200, input_D=56, input_H=448, input_W=448, resume_path='', pretrain_path='pretrain/resnet_50.pth', new_layer_names=['conv_seg'], no_cuda=False, gpu_id=[0], model='resnet', model_depth=50, resnet_shortcut='B', manual_seed=1, ci_test=False, save_folder='./trails/models/resnet_50', pin_memory=True)\n",
            "\n",
            "\n",
            "\n",
            "2024-11-08 14:38:11 INFO     [train.py:35] Start epoch 0\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:813: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  _warn_get_lr_called_within_step(self)\n",
            "2024-11-08 14:38:11 INFO     [train.py:38] lr = [0.0009801, 0.09801]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MedicalNet/train.py\", line 151, in <module>\n",
            "    train(data_loader, model, optimizer, scheduler, total_epochs=sets.n_epochs, save_interval=sets.save_intervals, save_folder=sets.save_folder, sets=sets) \n",
            "  File \"/content/MedicalNet/train.py\", line 40, in train\n",
            "    for batch_id, batch_data in enumerate(data_loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 715, in reraise\n",
            "    raise exception\n",
            "nibabel.deprecator.ExpiredDeprecationError: Caught ExpiredDeprecationError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/MedicalNet/datasets/brains18.py\", line 52, in __getitem__\n",
            "    img_array, mask_array = self.__training_data_process__(img, mask)\n",
            "  File \"/content/MedicalNet/datasets/brains18.py\", line 172, in __training_data_process__\n",
            "    data = data.get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nibabel/deprecator.py\", line 224, in deprecated_func\n",
            "    raise exception(message)\n",
            "nibabel.deprecator.ExpiredDeprecationError: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
            "\n",
            "* deprecated from version: 3.0\n",
            "* Raises <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --gpu_id 0 --resume_path trails/models/resnet_50_epoch_110_batch_0.pth.tar --img_list data/val.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJjRt2-2Nh_Z",
        "outputId": "cb0905ff-01c7-464c-e569-9518a320a023"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MedicalNet/test.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(sets.resume_path)\n",
            "/content/MedicalNet/models/resnet.py:173: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
            "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
            "Processing 2 datas\n",
            "./data/MRBrainS18/images/070.nii.gz\n",
            "./data/MRBrainS18/images/1.nii.gz\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MedicalNet/test.py\", line 92, in <module>\n",
            "    masks = test(data_loader, net, img_names, sets)\n",
            "  File \"/content/MedicalNet/test.py\", line 51, in test\n",
            "    for batch_id, batch_data in enumerate(data_loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1465, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1491, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils.py\", line 715, in reraise\n",
            "    raise exception\n",
            "nibabel.deprecator.ExpiredDeprecationError: Caught ExpiredDeprecationError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n",
            "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/MedicalNet/datasets/brains18.py\", line 71, in __getitem__\n",
            "    img_array = self.__testing_data_process__(img)\n",
            "  File \"/content/MedicalNet/datasets/brains18.py\", line 193, in __testing_data_process__\n",
            "    data = data.get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/nibabel/deprecator.py\", line 224, in deprecated_func\n",
            "    raise exception(message)\n",
            "nibabel.deprecator.ExpiredDeprecationError: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
            "\n",
            "* deprecated from version: 3.0\n",
            "* Raises <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWZcIi6iN1tk",
        "outputId": "888252bb-3890-49e9-b2ba-37e0da8c9d2e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after '/content/drive/MyDrive'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "from pathlib import Path\n",
        "import requests"
      ],
      "metadata": {
        "id": "-ISvp1_nTW7b"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install byaldi groq pdf2image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5q2-aziTaCt",
        "outputId": "3ac329bb-c710-41de-c67d-8ef0c2917ec9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: byaldi in /usr/local/lib/python3.10/dist-packages (0.0.5)\n",
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: colpali-engine<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from byaldi) (0.3.4)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from byaldi) (0.4.1)\n",
            "Requirement already satisfied: mteb==1.6.35 in /usr/local/lib/python3.10/dist-packages (from byaldi) (1.6.35)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from byaldi) (1.11.1.1)\n",
            "Requirement already satisfied: srsly in /usr/local/lib/python3.10/dist-packages (from byaldi) (2.4.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from byaldi) (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.42.0 in /usr/local/lib/python3.10/dist-packages (from byaldi) (4.46.2)\n",
            "Requirement already satisfied: datasets>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (3.1.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (1.13.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (3.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (4.66.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (13.9.3)\n",
            "Requirement already satisfied: pytrec-eval-terrier>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (0.5.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (4.12.2)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from mteb==1.6.35->byaldi) (0.2.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (10.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.10/dist-packages (from colpali-engine<0.4.0,>=0.3.1->byaldi) (1.4.0)\n",
            "Requirement already satisfied: peft<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from colpali-engine<0.4.0,>=0.3.1->byaldi) (0.11.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->mteb==1.6.35->byaldi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->mteb==1.6.35->byaldi) (2.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->byaldi) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->byaldi) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->byaldi) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->byaldi) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->byaldi) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->byaldi) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->byaldi) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->byaldi) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->byaldi) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->byaldi) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->byaldi) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->byaldi) (0.20.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from srsly->byaldi) (2.0.10)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.2.0->mteb==1.6.35->byaldi) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.2.0->mteb==1.6.35->byaldi) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.2.0->mteb==1.6.35->byaldi) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.2.0->mteb==1.6.35->byaldi) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.2.0->mteb==1.6.35->byaldi) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.2.0->mteb==1.6.35->byaldi) (3.10.10)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.1->byaldi) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft<0.12.0,>=0.11.0->colpali-engine<0.4.0,>=0.3.1->byaldi) (0.34.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->mteb==1.6.35->byaldi) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->mteb==1.6.35->byaldi) (2.2.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->mteb==1.6.35->byaldi) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->mteb==1.6.35->byaldi) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->byaldi) (3.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->mteb==1.6.35->byaldi) (24.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mteb==1.6.35->byaldi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mteb==1.6.35->byaldi) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.2.0->mteb==1.6.35->byaldi) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.2.0->mteb==1.6.35->byaldi) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.2.0->mteb==1.6.35->byaldi) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.2.0->mteb==1.6.35->byaldi) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.2.0->mteb==1.6.35->byaldi) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.2.0->mteb==1.6.35->byaldi) (4.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mteb==1.6.35->byaldi) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.2.0->mteb==1.6.35->byaldi) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.2.0->mteb==1.6.35->byaldi) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.2.0->mteb==1.6.35->byaldi) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.2.0->mteb==1.6.35->byaldi) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.2.0->mteb==1.6.35->byaldi) (0.2.0)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from byaldi import RAGMultiModalModel\n",
        "from groq import Groq\n",
        "from PIL import Image\n",
        "import io\n"
      ],
      "metadata": {
        "id": "qyPBXIfKTcG1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path"
      ],
      "metadata": {
        "id": "EPsETq7xTjbT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDlj4ngBTmfB",
        "outputId": "b3009f32-3ada-4353-b574-33ee22babc5f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/Tencent/MedicalNet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug5hXzzITp7I",
        "outputId": "8210fbe3-5f4e-40c7-cfe6-0d2cb19bbc66"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MedicalNet' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EQAbnHfTt2L",
        "outputId": "2aabafa7-54b7-447f-8028-d40fd2138f32"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download MedicalNet pretrained model\n",
        "!gdown --id 145ZEW3A6isY3gjYYiYomNj9Az-yVd-p_\n",
        "!unzip MedicalNet_pytorch_files2.zip -d /content/MedicalNet/ -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC6cAGmnTzd6",
        "outputId": "f94486ce-bc1e-42fa-d9d4-577bc2c32e53"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=145ZEW3A6isY3gjYYiYomNj9Az-yVd-p_\n",
            "From (redirected): https://drive.google.com/uc?id=145ZEW3A6isY3gjYYiYomNj9Az-yVd-p_&confirm=t&uuid=64802804-d6e9-46ce-ac81-6e003b7bc7c3\n",
            "To: /content/MedicalNet/MedicalNet_pytorch_files2.zip\n",
            "100% 2.80G/2.80G [00:22<00:00, 122MB/s]\n",
            "Archive:  MedicalNet_pytorch_files2.zip\n",
            "caution: filename not matched:  -y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from byaldi import RAGMultiModalModel\n",
        "from groq import Groq\n"
      ],
      "metadata": {
        "id": "3iVGMDkGW9kZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Groq RAG System Class\n",
        "class GroqRAGSystem:\n",
        "    def __init__(self, hf_token: str, groq_api_key: str, model_name: str = \"mixtral-8x7b-32768\"):\n",
        "        \"\"\"\n",
        "        Initialize the RAG system with Groq integration\n",
        "\n",
        "        Args:\n",
        "            hf_token: HuggingFace token for downloading ColPali\n",
        "            groq_api_key: Groq API key\n",
        "            model_name: Groq model to use (default: mixtral-8x7b-32768)\n",
        "        \"\"\"\n",
        "        # Initialize Groq client\n",
        "        self.groq_client = Groq(api_key=groq_api_key)\n",
        "        self.model_name = model_name\n",
        "\n",
        "        # Initialize RAG model\n",
        "        self.rag_model = RAGMultiModalModel.from_pretrained(\n",
        "            \"vidore/colpali-v1.2\",\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "    def prepare_pdf(self, pdf_path: str) -> None:\n",
        "        \"\"\"\n",
        "        Index a PDF document for retrieval\n",
        "\n",
        "        Args:\n",
        "            pdf_path: Path to the PDF file\n",
        "        \"\"\"\n",
        "        self.rag_model.index(\n",
        "            input_path=pdf_path,\n",
        "            index_name=Path(pdf_path).stem,\n",
        "            store_collection_with_index=True,\n",
        "            overwrite=True\n",
        "        )\n",
        "\n",
        "    def create_prompt(self, query: str, context_image: str) -> str:\n",
        "        return f\"\"\"You are an AI assistant helping to answer questions about documents.\n",
        "        The following image contains relevant context to answer the query.\n",
        "\n",
        "        Query: {query}\n",
        "\n",
        "        [Image Context (Base64 encoded): {context_image}]\n",
        "\n",
        "        Answer: \"\"\"\n",
        "\n",
        "    def query_document(self, query: str, k: int = 1) -> str:\n",
        "        results = self.rag_model.search(query, k=k)\n",
        "\n",
        "        if not results:\n",
        "            return \"No relevant results found.\"\n",
        "\n",
        "        # Get the image from top result\n",
        "        image_bytes = base64.b64decode(results[0].base64)\n",
        "        image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "        # Create prompt with context\n",
        "        prompt = self.create_prompt(query, image_base64)\n",
        "\n",
        "        # Query Groq\n",
        "        completion = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that can understand and analyze document images.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.1,\n",
        "            max_tokens=500\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hfNd4MZOR2L0"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Example usage\n",
        "    groq_api_key = \"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\"\n",
        "    hf_token = \"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\"\n",
        "\n",
        "    # Initialize the system\n",
        "    rag_system = GroqRAGSystem(\n",
        "        hf_token=hf_token,\n",
        "        groq_api_key=groq_api_key\n",
        "    )\n",
        "\n",
        "    # Prepare a PDF document\n",
        "    pdf_path = r\"/content/Sample-filled-in-MR-1-2.pdf\"\n",
        "    rag_system.prepare_pdf(pdf_path)\n",
        "\n",
        "    # Query the document\n",
        "    query = \"What's the BLEU score for the transformer base model?\"\n",
        "    response = rag_system.query_document(query)\n",
        "    print(f\"Query: {query}\\nResponse: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "af678947a58e493599351c88bef2ca8b",
            "1be715a9b1ff474eb21248862a42dda2",
            "20f140c2329c445f9d9b2a6a5ec2e3a1",
            "0806e3f728814596977d6842e93e207d",
            "493587d9a56f429796e6b03bde7dab2b",
            "b9685321472d49178d5bab06c826c9e2",
            "f7fd79d431524b988bcbb0a801127314",
            "f2f4feddc51c4d77a5eeb9ad82f6b907",
            "b9c4967ecb6f46899dd2cf34305eead1",
            "96c3d1dbce0b4115a947d959d95ec991",
            "e563bcc4d44244cd8bb3a58d2ace20c1"
          ]
        },
        "id": "Gj3JmgXDcDyp",
        "outputId": "b1f46698-b395-4acb-8c2c-38a84fed5453"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af678947a58e493599351c88bef2ca8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1006.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 33.06 MiB is free. Process 7845 has 14.71 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 144.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-38524ad34d87>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-38524ad34d87>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Initialize the system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     rag_system = GroqRAGSystem(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mhf_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mgroq_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroq_api_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-88c166670ce9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hf_token, groq_api_key, model_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Initialize RAG model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         self.rag_model = RAGMultiModalModel.from_pretrained(\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;34m\"vidore/colpali-v1.2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/byaldi/RAGModel.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, index_root, device, verbose)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m     58\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         instance.model = ColPaliModel.from_pretrained(\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mindex_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/byaldi/colpali.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, n_gpu, verbose, device, index_root, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     ):\n\u001b[0;32m--> 209\u001b[0;31m         return cls(\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mn_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/byaldi/colpali.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pretrained_model_name_or_path, n_gpu, index_name, verbose, load_from_index, index_root, device, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"colpali\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             self.model = ColPali.from_pretrained(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4223\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4224\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4225\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4226\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4227\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4726\u001b[0m                                 )\n\u001b[1;32m   4727\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4728\u001b[0;31m                         new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   4729\u001b[0m                             \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4730\u001b[0m                             \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0;31m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m             \u001b[0mset_module_tensor_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mset_module_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_quantized_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    414\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1006.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 33.06 MiB is free. Process 7845 has 14.71 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 144.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MedicalNet Model Class\n",
        "class MedicalNetInference:\n",
        "    def __init__(self, model_path: str):\n",
        "        self.model = self.load_model(model_path)\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        opt = parse_opts()\n",
        "        opt.model_depth = 50\n",
        "        opt.resnet_shortcut = 'B'\n",
        "        opt.sample_duration = 64\n",
        "        model = generate_model(opt)\n",
        "        checkpoint = torch.load(model_path, map_location='cpu')\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def run_inference(self, input_tensor):\n",
        "        with torch.no_grad():\n",
        "            output = self.model(input_tensor)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "OAmCTUttTxmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Function to Process PDF and Query\n",
        "def main():\n",
        "    hf_token = \"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\"\n",
        "    groq_api_key = \"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\"\n",
        "\n",
        "    # Initialize the models\n",
        "    medical_model_path = \"/content/MedicalNet/pretrained_model.pth\"\n",
        "    groq_rag_system = GroqRAGSystem(hf_token=hf_token, groq_api_key=groq_api_key)\n",
        "    medicalnet_inference = MedicalNetInference(model_path=medical_model_path)\n",
        "\n",
        "    # PDF processing and query\n",
        "    pdf_path = \"/content/drive/MyDrive/Sample-filled-in-MR.pdf\"\n",
        "    groq_rag_system.prepare_pdf(pdf_path)\n",
        "\n",
        "    # Convert PDF to images for MedicalNet inference\n",
        "    images = convert_from_path(pdf_path, dpi=300)\n",
        "    for i, image in enumerate(images):\n",
        "        image_tensor = preprocess_image_for_model(image)\n",
        "        medical_output = medicalnet_inference.run_inference(image_tensor)\n",
        "        print(f\"MedicalNet Inference for Page {i+1}: {medical_output}\")\n",
        "\n",
        "    # Query GroqRAG system for further details\n",
        "    query = \"Extract diagnosis details and summary.\"\n",
        "    response = groq_rag_system.query_document(query)\n",
        "    print(f\"Query: {query}\\nResponse: {response}\")\n",
        "\n",
        "def preprocess_image_for_model(image):\n",
        "    # Convert PIL image to tensor suitable for MedicalNet\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),  # Example resizing\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Rmpvbr3MS0Gw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}